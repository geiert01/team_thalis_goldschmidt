{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a5808df077715eb",
   "metadata": {},
   "source": [
    "# AIM Hackathon: Sample code\n",
    "19.10.2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8bec73e3a0cd2571",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T08:42:29.779608Z",
     "start_time": "2024-10-18T08:42:26.029795Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import PyPDF2\n",
    "import tiktoken\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from dotenv import load_dotenv\n",
    "from tqdm import tqdm\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.documents import Document\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_openai.embeddings.base import OpenAIEmbeddings\n",
    "\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.vectorstores import FAISS\n",
    "\n",
    "from Cryptodome.Cipher import AES\n",
    "\n",
    "from typing import Optional, List, Union\n",
    "from pydantic import BaseModel\n",
    "from openai import OpenAI\n",
    "\n",
    "# load openai key\n",
    "if not load_dotenv():\n",
    "    raise Exception('Error loading .env file. Make sure to place a valid OPEN_AI_KEY in the .env file.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ca3544d9e60a0cf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T08:45:34.765879Z",
     "start_time": "2024-10-18T08:45:34.751838Z"
    }
   },
   "outputs": [],
   "source": [
    "REPORTS_SAVE_PATH = 'data/sample_reports'\n",
    "DB_PATH = \"data/db/sample.db\"\n",
    "\n",
    "# See https://openai.com/api/pricing/\n",
    "MODEL = \"gpt-4o\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "884c8d201075524d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T08:45:35.123394Z",
     "start_time": "2024-10-18T08:45:35.064870Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company_name</th>\n",
       "      <th>year</th>\n",
       "      <th>dataset</th>\n",
       "      <th>pdf_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Walmart</td>\n",
       "      <td>2023</td>\n",
       "      <td>handcrafted</td>\n",
       "      <td>https://corporate.walmart.com/content/dam/corp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Walmart</td>\n",
       "      <td>2021</td>\n",
       "      <td>handcrafted</td>\n",
       "      <td>https://corporate.walmart.com/content/dam/corp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Walmart</td>\n",
       "      <td>2019</td>\n",
       "      <td>handcrafted</td>\n",
       "      <td>https://corporate.walmart.com/content/dam/corp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Amazon</td>\n",
       "      <td>2023</td>\n",
       "      <td>handcrafted</td>\n",
       "      <td>https://sustainability.aboutamazon.com/content...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Amazon</td>\n",
       "      <td>2021</td>\n",
       "      <td>handcrafted</td>\n",
       "      <td>https://sustainability.aboutamazon.com/content...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>tarkett</td>\n",
       "      <td>2020</td>\n",
       "      <td>scraped</td>\n",
       "      <td>https://www.tarkett.com/sites/default/files/20...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>trivium-packaging</td>\n",
       "      <td>2021</td>\n",
       "      <td>scraped</td>\n",
       "      <td>https://www.triviumpackaging.com/media/13fl4q3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>trivium-packaging</td>\n",
       "      <td>2020</td>\n",
       "      <td>scraped</td>\n",
       "      <td>https://triviumpackaging.com/sustainability/re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>trust</td>\n",
       "      <td>2023</td>\n",
       "      <td>scraped</td>\n",
       "      <td>https://dezlwerqy1h00.cloudfront.net/images/co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>trust</td>\n",
       "      <td>2021</td>\n",
       "      <td>scraped</td>\n",
       "      <td>https://dezlwerqy1h00.cloudfront.net/images/co...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>146 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          company_name  year      dataset  \\\n",
       "0              Walmart  2023  handcrafted   \n",
       "1              Walmart  2021  handcrafted   \n",
       "2              Walmart  2019  handcrafted   \n",
       "3               Amazon  2023  handcrafted   \n",
       "4               Amazon  2021  handcrafted   \n",
       "..                 ...   ...          ...   \n",
       "141            tarkett  2020      scraped   \n",
       "142  trivium-packaging  2021      scraped   \n",
       "143  trivium-packaging  2020      scraped   \n",
       "144              trust  2023      scraped   \n",
       "145              trust  2021      scraped   \n",
       "\n",
       "                                               pdf_url  \n",
       "0    https://corporate.walmart.com/content/dam/corp...  \n",
       "1    https://corporate.walmart.com/content/dam/corp...  \n",
       "2    https://corporate.walmart.com/content/dam/corp...  \n",
       "3    https://sustainability.aboutamazon.com/content...  \n",
       "4    https://sustainability.aboutamazon.com/content...  \n",
       "..                                                 ...  \n",
       "141  https://www.tarkett.com/sites/default/files/20...  \n",
       "142  https://www.triviumpackaging.com/media/13fl4q3...  \n",
       "143  https://triviumpackaging.com/sustainability/re...  \n",
       "144  https://dezlwerqy1h00.cloudfront.net/images/co...  \n",
       "145  https://dezlwerqy1h00.cloudfront.net/images/co...  \n",
       "\n",
       "[146 rows x 4 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_json('data/reports.json')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "691b3873627faac",
   "metadata": {},
   "source": [
    "## Download some reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7016c71d2e6c157c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T08:45:36.892663Z",
     "start_time": "2024-10-18T08:45:36.882663Z"
    }
   },
   "outputs": [],
   "source": [
    "# EXAMPLE: select apple reports\n",
    "df_sample = df[df['dataset']=='handcrafted']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5f11fde1d1812112",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T08:45:37.365944Z",
     "start_time": "2024-10-18T08:45:37.344942Z"
    }
   },
   "outputs": [],
   "source": [
    "# Storing the encryption keys for further decryption\n",
    "enc_keys = []\n",
    "\n",
    "# download Apple reports to save_dir\n",
    "def download_files(df: pd.DataFrame, save_dir: str):\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    for url in df['pdf_url']:\n",
    "        pdf_filename = os.path.basename(url)\n",
    "        # Checking if the file is encrypted\n",
    "        if('?' in pdf_filename):\n",
    "            # Saving the password for decryption\n",
    "            enc_keys.append(pdf_filename)\n",
    "            # Removing question mark\n",
    "            pdf_filename = pdf_filename.split('?')[0]\n",
    "            \n",
    "        response = requests.get(url)\n",
    "        with open(os.path.join(save_dir, pdf_filename), 'wb') as file:\n",
    "            file.write(response.content)\n",
    "    print(f\"Success.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cb4a2407fec641",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success.\n"
     ]
    }
   ],
   "source": [
    "download_files(df_sample, REPORTS_SAVE_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f93afeb4f8e422c6",
   "metadata": {},
   "source": [
    "## Create simple vector database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "42eeec6e365fd353",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T08:45:58.246571Z",
     "start_time": "2024-10-18T08:45:58.230622Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_password(f):\n",
    "    for tmp in enc_keys:\n",
    "        if(f == tmp.split()[0]):\n",
    "            return tmp\n",
    "\n",
    "def get_documents_from_path(files_path: str) -> [Document]:\n",
    "    documents = []\n",
    "    \n",
    "    for file in os.listdir(files_path):\n",
    "        _, file_extension = os.path.splitext(file)\n",
    "        text = \"\"\n",
    "        \n",
    "        if file_extension == \".pdf\":\n",
    "            with open(os.path.join(files_path, file), 'rb') as f:\n",
    "                reader = PyPDF2.PdfReader(f, strict=False)\n",
    "                \n",
    "                if reader.is_encrypted:\n",
    "                    try:\n",
    "                        # Try to decrypt with the provided password (or an empty string if no password is given)\n",
    "                        pdf_password = get_password(file)\n",
    "                        \n",
    "                        if pdf_password:\n",
    "                            success = reader.decrypt(pdf_password)\n",
    "                        else:\n",
    "                            success = reader.decrypt(\"\")\n",
    "\n",
    "                        if success == 0:\n",
    "                            print(f\"Failed to decrypt {file}: Invalid password.\")\n",
    "                            continue  # Skip file if decryption fails\n",
    "                        else:\n",
    "                            print(f\"Decrypted {file} successfully.\")\n",
    "                    except Exception as e:\n",
    "                        print(f\"Failed to decrypt {file}: {e}\")\n",
    "                        continue  # Skip file if decryption fails\n",
    "                for page in reader.pages:\n",
    "                    text += page.extract_text() + \"\\n\"\n",
    "                \n",
    "            if text:\n",
    "                documents.append(Document(page_content=text, metadata={\"source\": file}))\n",
    "            else:\n",
    "                print(f\"WARNING: No text extracted from {file}\")\n",
    "        else:\n",
    "            # TODO: can add support for other file types here\n",
    "            raise Exception(f\"Unsupported file extension: {file_extension}\")\n",
    "    \n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c0705d007aae0741",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T08:46:27.182748Z",
     "start_time": "2024-10-18T08:45:58.503064Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decrypted 2023_Volkswagen_Group_Sustainability_Report.pdf successfully.\n",
      "Decrypted bp-sustainability-report-2021.pdf successfully.\n",
      "Decrypted bp-sustainability-report-2023.pdf successfully.\n",
      "Decrypted Nonfinancial_Report_2021_en.pdf successfully.\n"
     ]
    }
   ],
   "source": [
    "documents = get_documents_from_path(REPORTS_SAVE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6bc507f61c0167c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO could also just provide a dummy retriever to not spoil too much\n",
    "class DummyRetriever:\n",
    "    def __init__(self, texts):\n",
    "        self.texts = texts\n",
    "        \n",
    "    def dummy_retriever(self, query):\n",
    "        import random\n",
    "        return random.sample(self.texts, k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6af1ec858814862b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T08:46:39.300669Z",
     "start_time": "2024-10-18T08:46:27.184677Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count: 1286489\n"
     ]
    }
   ],
   "source": [
    "# Create database\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=3000, chunk_overlap=300, separators=[\"\\n\\n\", \"\\n\"])\n",
    "\n",
    "# split documents and create vector database\n",
    "texts = text_splitter.split_documents(documents)\n",
    "embeddings = OpenAIEmbeddings()  # https://platform.openai.com/docs/guides/embeddings/embedding-models\n",
    "db = FAISS.from_documents(texts, embeddings)\n",
    "\n",
    "# count build embedding token number\n",
    "tokenizer = tiktoken.get_encoding(\"cl100k_base\")\n",
    "build_token_count = sum([len(tokenizer.encode(doc.page_content)) for doc in texts])\n",
    "print(f\"Token count: {build_token_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fba814c7f46c5b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store the database\n",
    "with open(DB_PATH, \"wb\") as f:\n",
    "    pickle.dump(db.serialize_to_bytes(), f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2816a3db31f23fa",
   "metadata": {},
   "source": [
    "## Create simple RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "58dd89c06d4a0a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the database\n",
    "DB_PATH = \"data/db/sample.db\"\n",
    "\n",
    "with open(DB_PATH, \"rb\") as f:\n",
    "    db_bytes = pickle.load(f)\n",
    "    db = FAISS.deserialize_from_bytes(db_bytes, OpenAIEmbeddings(), allow_dangerous_deserialization=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7013c323",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI()\n",
    "\n",
    "retriever=db.as_retriever()\n",
    "\n",
    "class Answer(BaseModel):\n",
    "    value: Optional[List[Union[float, int]]]\n",
    "    unit: str\n",
    "    chain_of_thought: str\n",
    "\n",
    "def retrieve_context(question):\n",
    "    context_docs = retriever.get_relevant_documents(question)\n",
    "    context = '\\n'.join([doc.page_content for doc in context_docs])\n",
    "    return context\n",
    "\n",
    "def construct_messages(context, question):\n",
    "    system_prompt = (\n",
    "        \"You are an expert assistant. Use only the following retrieved context to answer the question accurately and concisely. \"\n",
    "        \"Provide your answer as a number followed by its unit, without any additional text or explanation. \"\n",
    "        \"Before giving the final answer, include your chain-of-thought reasoning prefixed with 'Chain of Thought:'. \"\n",
    "        \"If nothing is mentioned in the context, say 'I don't know'.\"\n",
    "    )\n",
    "    \n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": f\"Context:\\n{context}\\n\\nQuestion:\\n{question}\"}\n",
    "    ]\n",
    "    return messages\n",
    "\n",
    "def get_response_from_openai(question):\n",
    "    context = retrieve_context(question)\n",
    "    messages = construct_messages(context, question)\n",
    "    completion = client.beta.chat.completions.parse(\n",
    "        model=MODEL,\n",
    "        messages=messages,\n",
    "        response_format=Answer\n",
    "        )\n",
    "    return completion.choices[0].message.parsed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "38f95807",
   "metadata": {},
   "outputs": [],
   "source": [
    "esg_metrics = [\n",
    "    'Carbon Emissions',\n",
    "    'Energy Consumption',\n",
    "    'Water Usage',\n",
    "    'Waste Generation',\n",
    "    'Renewable Energy Usage',\n",
    "    'Greenhouse Gas Emissions Intensity',\n",
    "    'Biodiversity Impact',\n",
    "    'Air Pollutant Emissions',\n",
    "    'Environmental Management System',\n",
    "    'Supply Chain Environmental Impact',\n",
    "    'Employee Turnover Rate',\n",
    "    'Gender Diversity Ratio',\n",
    "    'Employee Health and Safety Incidents',\n",
    "    'Labor Practices',\n",
    "    'Human Rights Compliance',\n",
    "    'Community Engagement Initiatives',\n",
    "    'Customer Satisfaction Score',\n",
    "    'Data Privacy Breaches',\n",
    "    'Product Safety Incidents',\n",
    "    'Board Diversity',\n",
    "    'Executive Compensation Ratio',\n",
    "    'Shareholder Rights',\n",
    "    'Anti-Corruption Policies',\n",
    "    'Regulatory Compliance',\n",
    "    'Ethical Supply Chain Management',\n",
    "    'Stakeholder Engagement',\n",
    "    'Risk Management Strategies',\n",
    "    'Transparency and Disclosure Practices',\n",
    "    'Climate Change Risks and Opportunities',\n",
    "    'Innovation and R&D Investment'\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d30698ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Answer(value=[2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018], unit='years', chain_of_thought='Chain of Thought: The data on CO2 emissions for Apple is provided for fiscal years 2011 through 2018. The table lists emissions for each of these years with detailed breakdowns for different locations and components, indicating that we have specific data for these years.')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_response_from_openai(f\"in which years do we have data on co2 emission for Apple?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "cee625b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The companies are: Amazon, H&M, Apple, BP, Walmart, Saudi Aramco, Google, Volkswagen\n",
      "Amazon (2022) - Carbon Emissions: value=[70.74] unit='metric tons CO2e' chain_of_thought='The carbon emissions for Amazon in 2022 is given as 70.74M metric tons CO2e.'\n",
      "H&M (2016) - Carbon Emissions: value=[10376, 70165] unit='tonnes' chain_of_thought='Chain of Thought: The context provides cumulative scope 1 and scope 2 emissions for multiple years, but data for 2016 is missing. Therefore, without specific numbers for 2016 in the context, I look at the provided data for the subsequent years. The data includes both Scope 1 and Scope 2 emissions. In 2016, the provided numbers for total scope 1 and 2 CO2e emissions are not explicitly mentioned. Hence, I will consider the mentioned total scope 1 and scope 2 emissions for the closest year available that is clearly designated, which is 2018. \\nScope 1 and 2 CO2e emissions for 2018 are: \\nScope 1: 10,376 tonnes \\nScope 2: 70,165 tonnes \\nTotal for 2018: 80,541 tonnes. \\nThus, given the lack of specific data for 2016, I will provide the figures for the earliest year presented, which would be the provisional figures, assuming a total calculation prior to adjustments or extrapolations in context: \\nScope 1: 10,376 tonnes \\nScope 2: 70,165 tonnes. \\nConclusion: Total Scope 1 emissions is 10,376 tonnes and Scope 2 emissions is 70,165 tonnes.'\n",
      "H&M (2017) - Carbon Emissions: value=[70165] unit='tonnes' chain_of_thought='From the given data, we can identify the total Scope 2 CO2e emissions for the year 2017. The data lists emissions for each year, and the 2017 emissions are specified as 70,165 tonnes. Therefore, the carbon emissions for H&M in 2017 are 70,165 tonnes.'\n",
      "H&M (2018) - Carbon Emissions: value=[6352, 775, 71, 62, 63] unit='ktonnes' chain_of_thought=\"The context provides the total Scope 1 and 2 CO2e emissions, including renewables, for 2018 as 56,978 tonnes. It also provides Scope 3 CO2e emissions for 2019 as 17,662 kilotonnes. Since no specific numbers for Scope 3 emissions for 2018 and the total carbon emissions for 2018 are provided in the context, I can't calculate the total carbon emissions for H&M in 2018. Moreover, the final required number could include Scope 1, 2, and potentially 3 emissions for a complete carbon emissions assessment. I don't have enough data to arrive at the total carbon emissions for H&M in 2018. Therefore, I must conclude with 'I don't know.'\"\n",
      "H&M (2019) - Carbon Emissions: value=[10, 376, 70, 165, 80, 541, 12, 484, 51, 206, 63, 690, 11, 818, 45, 160, 56, 978, 13, 380, 48, 82, 61, 462] unit='tonnes' chain_of_thought=\"The scope 1 and 2 CO2e emissions for 2019 are given in the context, but they are mixed with other years' data. By examining the data closely, we can isolate the 2019 figures by considering the description and typical reporting format given for scope 1 & 2 emissions as separate annual totals.\"\n",
      "Apple (2012) - Carbon Emissions: value=[400000] unit='metric tons CO2e' chain_of_thought=\"The data provides the trend of Apple emissions in metric tons CO2e for fiscal years from FY '11 through FY '19. For FY '12, the chart indicates 400,000 metric tons CO2e.\"\n",
      "Apple (2011) - Carbon Emissions: value=[200000] unit='metric tons CO2e' chain_of_thought='Looking at the provided data, the carbon emissions for Apple in 2011 are depicted as the starting point of the time series graph with the noted metric tonnage. The graph indicates 200,000 metric tons CO2e for that year.'\n",
      "BP (2017) - Carbon Emissions: value=[48.8] unit='MteCO2e' chain_of_thought='Chain of Thought: According to the context provided, the operational control Scope 1 (direct) emissions for BP in 2018 were reported at 48.8 MteCO2e. Since the context notes an increase in emissions from 2018 to 2019 but does not specify 2017 emissions, it can be logically inferred that 48.8 MteCO2e might also be applicable for 2017 or close to it, barring any explicit mention. Therefore, I will use this figure.'\n",
      "BP (2018) - Carbon Emissions: value=[46.5, 5.7] unit='MteCO2e' chain_of_thought=\"Chain of Thought: BP's Scope 1 (direct) emissions in 2018 were 46.5 MteCO2e, and Scope 2 (indirect) emissions were 5.7 MteCO2e.\"\n",
      "BP (2019) - Carbon Emissions: value=[50.5, 5.2] unit='MteCO2e' chain_of_thought=\"The document lists BP's operational carbon emissions for 2019 by breaking them into components: Scope 1 (direct) GHG emissions under the operational boundary is 50.5 MteCO2e and Scope 2 (indirect) GHG emissions under the same boundary is 5.2 MteCO2e. Summing these gives a total emissions of 55.7 MteCO2e.\"\n",
      "BP (2022) - Carbon Emissions: value=[30.4] unit='MtCO2e' chain_of_thought=\"Chain of Thought: From the context, it states that in 2023, BP's Scope 1 (direct) emissions were 31.1MtCO2e, an increase from 30.4MtCO2e in 2022. Therefore, the Carbon Emissions for BP in 2022 were 30.4MtCO2e.\"\n",
      "BP (2023) - Carbon Emissions: value=[31.1, 1.0] unit='MtCO2e' chain_of_thought=\"Chain of Thought: BP's total carbon emissions for 2023 are given as 31.1 MtCO2e for Scope 1 emissions (which include 30.2 MtCO2e of carbon dioxide and 1.0 MtCO2e of methane). Additionally, Scope 2 emissions are stated separately as 1.0 MtCO2e, making the total emissions 32.1 MtCO2e. However, since the question asks for carbon emissions specifically, we should consider only the carbon dioxide component which is 31.1 MtCO2e.\"\n",
      "Walmart (2015) - Carbon Emissions: value=[21.69] unit='Million Metric Tons (MT) CO2e' chain_of_thought='Chain of Thought: In 2015, the carbon emissions for Walmart include both Scope 1 and Scope 2 emissions. The Scope 1 emissions were 6.76 Million MT CO2e and Scope 2 emissions were 14.93 Million MT CO2e. Adding these together gives a total of 21.69 Million MT CO2e.'\n",
      "Walmart (2017) - Carbon Emissions: value=[12.16, 6.52] unit='Million MT CO₂e' chain_of_thought='Chain of Thought: From the context, we see the annual greenhouse gas emissions for Walmart split into Scope 1 and Scope 2. For 2017, Scope 1 is 6.52 Million MT CO₂e and Scope 2 is 12.16 Million MT CO₂e. Adding both gives the total carbon emissions for 2017.'\n",
      "Walmart (2018) - Carbon Emissions: value=[12.16, 6.52] unit='Million MT CO₂e' chain_of_thought='The carbon emissions for Walmart in 2018 for Scope 1 is 6.52 Million MT CO₂e and for Scope 2 is 12.16 Million MT CO₂e. Together, this totals to 18.68 Million MT CO₂e.'\n",
      "Saudi Aramco (2022) - Carbon Emissions: value=[55.7, 16.1] unit='million metric tons of CO2e' chain_of_thought=\"In 2022, Saudi Aramco's carbon emissions consisted of Scope 1 and Scope 2 emissions. From the provided context, the Scope 1 emissions are recorded as 55.7 million metric tons of CO2e and the Scope 2 emissions (location-based) are 16.1 million metric tons of CO2e.\"\n",
      "Saudi Aramco (2023) - Carbon Emissions: value=[54.4, 18.2] unit='million metric tons of CO2e' chain_of_thought='Chain of Thought: To find the carbon emissions for Saudi Aramco, we need to consider both the Scope 1 and Scope 2 emissions. In 2023, the Scope 1 emissions were 54.4 million metric tons of CO2e. The Scope 2 emissions, which are location-based, were 18.2 million metric tons of CO2e. Therefore, the total carbon emissions for Saudi Aramco in 2023 would be the sum of Scope 1 and Scope 2 emissions (location-based).'\n",
      "Google (2016) - Carbon Emissions: value=[6.1] unit='million tCO2e' chain_of_thought='The context provides GHG emissions for Google in 2018 without renewable energy purchases as 4.4 million tCO2e. However, for 2016, the GHG emissions without renewable energy purchases are visually shown in Figure 7 as approximately 6.1 million tCO2e. Since we are asked for emissions in 2016 specifically, I referred to the visual information provided for that year.'\n",
      "Google (2018) - Carbon Emissions: value=[4400000] unit='tCO2e' chain_of_thought=\"The context states that Google's gross Scope 1 and 2 GHG emissions in 2018 were 4.4 million metric tons of carbon dioxide equivalent (tCO2e). Therefore, the carbon emissions for Google in 2018 is 4.4 million tCO2e.\"\n",
      "Volkswagen (2023) - Carbon Emissions: value=[133] unit='g CO₂/km' chain_of_thought='The average GHG CO₂ value for the passenger car and light commercial vehicle fleets in model year 2023 is given as 133 g CO₂/km.'\n",
      "Volkswagen (2022) - Carbon Emissions: value=[142] unit='g CO₂/km' chain_of_thought='According to the context provided, the average carbon emissions for Volkswagen passenger cars and light commercial vehicles in the USA for model year 2022 is 142 g CO₂/km.'\n",
      "Volkswagen (2021) - Carbon Emissions: value=[119] unit='g/km' chain_of_thought=\"Chain of Thought: The context provides information on CO₂ emissions for different markets and years. It mentions CO₂ emissions for different vehicle types in different regions. For the year 2021, the CO₂ emissions for the Volkswagen Group's European passenger car fleet are listed as 119 g/km.\"\n",
      "Volkswagen (2020) - Carbon Emissions: value=[151, 119] unit='g CO₂/km' chain_of_thought='Chain of Thought: In the USA for 2020, the passenger car and light commercial vehicle fleet’s GHG CO₂ figure is an average of 151 g CO₂/km. In the EU, the new passenger car fleet emitted an average of 119 g CO₂/km in 2020 (WLTP).'\n",
      "H&M (2017) - Energy Consumption: value=[11, 818, 45, 160] unit='tonnes CO2e' chain_of_thought=\"The energy consumption within H&M's own operations in 2017 is represented by the CO2 emissions for Scope 1 and Scope 2. According to the data provided, in 2017, the total CO2e emissions were 11,818 tonnes for Scope 1 and 45,160 tonnes for Scope 2. These numbers can be used to assess the energy consumption of H&M for that year.\"\n",
      "Apple (2018) - Energy Consumption: value=[113000000, 2500000] unit='kWh, therms' chain_of_thought='Chain of Thought: In fiscal year 2018, Apple cumulatively saved over 113 million kWh of electricity and 2.5 million therms of natural gas per year.'\n",
      "Google (2018) - Energy Consumption: value=[4464000000] unit='kWh' chain_of_thought=\"Chain of Thought: In 2018, Google's gross Scope 1 and 2 GHG emissions were 4.4 million metric tons of carbon dioxide equivalent (tCO2e), but this doesn't directly translate into energy consumption. However, Google's data centers had an average PUE of 1.11. Assuming electricity as the primary source, the electricity consumed can be estimated if total emissions and grid emission factors were available. But with current information, the exact energy consumption in kilowatt-hours (kWh) isn't provided. From referenced similar reports or databases, Google's estimated energy use could have been between 4 and 5 billion kWh based on typical values from past years and growth trends. Without exact figures in the context, we adopt a midpoint estimate based on trends.\\n\\nApproximately 4,464,000,000 kWh (considering data growth and typical efficiency improvement trends).\"\n",
      "Google (2020) - Energy Consumption: value=[18] unit='billion kWh' chain_of_thought='Chain of Thought: In 2020, the context states that Nest thermostats helped customers save more than 18 billion kWh of energy, which is explicitly mentioned as more energy than Google used in that year.'\n",
      "Volkswagen (2022) - Energy Consumption: value=[21.62] unit='million MWh' chain_of_thought='Chain of Thought: The energy consumption for the Volkswagen Group is mentioned as 21.62 million MWh for the year 2022.'\n",
      "Amazon (2021) - Water Usage: value=[0.25, 0.0038709677419354834] unit='Liters' chain_of_thought=\"The context provided does not specify the total water usage for Amazon in the year 2021. It mentions a 28% improvement in water use effectiveness (WUE) for AWS data centers from 2021 to 2023, achieving a WUE of 0.18 liters per kilowatt-hour. However, without the WUE of 2021 or total kilowatt-hour data, we can't derive the total water usage for Amazon in 2021. Therefore, I don't know the water usage for 2021.\"\n",
      "Amazon (2023) - Water Usage: value=[0.18] unit='Liters per kilowatt-hour (L/kWh)' chain_of_thought='The water usage effectiveness (WUE) for AWS data centers in 2023 is 0.18 L/kWh. This measurement reflects the efficiency of water usage in AWS data centers.'\n",
      "H&M (2017) - Water Usage: value=[24] unit='l/pc' chain_of_thought='Chain of Thought: The 2017 baseline for water usage per unit of product is provided in the context. The figure is 24 litres per unit of product for 2017.'\n",
      "H&M (2018) - Water Usage: value=[24, 20, 18] unit='l/pc, l/m, l/kg' chain_of_thought=\"The water usage for H&M in 2018 is specified as a 'litre per unit of product (l/pc)', 'litre per metre of fabric (l/m)', and 'litre per kg dyed fabric (l/kg)'. In 2018, these values are 24 l/pc, 20 l/m, and 18 l/kg respectively.\"\n",
      "H&M (2019) - Water Usage: value=[104] unit='l/kg' chain_of_thought='From the provided context, in 2019, the water usage for H&M is mentioned as 104 l/kg.'\n",
      "Apple (2017) - Water Usage: value=[1.26] unit='billion gallons' chain_of_thought=\"The text mentions that in fiscal year 2018, Apple used about 1.26 billion gallons of water directly. It also mentions that there was an increase in water use from the previous year, 2017. However, it doesn't explicitly state the water usage for 2017. Since we are inferring from the 2018 data, and there's no specific value given for 2017, we'll assume that the 2018 figure of 1.26 billion gallons represents the water usage at that time, and it's reasonable to assume 2017 usage would be slightly less given the stated increase.\"\n",
      "Apple (2018) - Water Usage: value=[1258] unit='million gallons' chain_of_thought=\"From the context, Apple's total water usage in 2018 at corporate facilities was 1258 million gallons.\"\n",
      "Apple (2022) - Water Usage: value=[1527] unit='million gallons' chain_of_thought=\"The table provided in the context lists the Total Water Usage for Apple's Corporate facilities in different fiscal years.\\nFor 2022, the Total Water Usage is given as 1,527 million gallons.\"\n",
      "Apple (2021) - Water Usage: value=[1407] unit='million gallons' chain_of_thought=\"The context provides a summary of Apple's corporate water usage in different fiscal years. Specifically for 2021, it lists the total water usage as 1,407 million gallons.\"\n",
      "BP (2016) - Water Usage: value=[256.5] unit='million m3' chain_of_thought='In the context, it is mentioned that in 2016, the total freshwater withdrawals by BP were 256.5 million m3.'\n",
      "Saudi Aramco (2021) - Water Usage: value=[33.8] unit='million cubic meters' chain_of_thought=\"Chain of Thought: From the context, in 2021, Saudi Aramco's freshwater consumption (FWC) was 33.8 million cubic meters, which is their water usage figure.\"\n",
      "Saudi Aramco (2020) - Water Usage: value=[32.9] unit='million cubic meters' chain_of_thought='In 2020, the freshwater consumption for Saudi Aramco was listed as 32.9 million cubic meters. This aligns with the query regarding water usage, assuming the usage refers to freshwater consumption.'\n",
      "Saudi Aramco (2023) - Water Usage: value=[135.7] unit='million m3' chain_of_thought=\"In 2023, Aramco's reported freshwater withdrawal was 135.7 million m3. This information is taken as water usage since no other specific metric for 'Water Usage' was provided.\"\n",
      "Saudi Aramco (2022) - Water Usage: value=[93.6] unit='million cubic meters' chain_of_thought='According to the context, freshwater consumption for Saudi Aramco in 2022 was 93.6 million cubic meters.'\n",
      "Google (2022) - Water Usage: value=[5.6] unit='billion gallons' chain_of_thought=\"The context states that in 2022, the total water consumption at Google's data centers and offices was 5.6 billion gallons.\"\n",
      "Volkswagen (2023) - Water Usage: value=[37.41] unit='million m³/year' chain_of_thought='Water withdrawal for the Volkswagen Group in 2023 is given as 37.41 million m³/year.'\n",
      "Amazon (2018) - Waste Generation: value=[375000] unit='metric tons' chain_of_thought='The context provides the supply chain waste diverted from landfill for the years 2017 to 2020 as follows:\\n- 2020: 400,000 metric tons\\n- 2019: 322,000 metric tons\\n- 2018: 375,000 metric tons\\n- 2017: 351,000 metric tons\\nThe waste generation for Amazon in 2018 is therefore 375,000 metric tons.'\n",
      "Apple (2020) - Waste Generation: value=[74000] unit='metric tons' chain_of_thought='The context indicates that in fiscal year 2018, Apple generated 74,000 metric tons of waste. However, the waste generation amount for 2020 is not directly provided in the context. Therefore, based on the available context, 74,000 metric tons is the available reference figure for waste generation.'\n",
      "Apple (2018) - Waste Generation: value=[74000] unit='metric tons' chain_of_thought='According to the provided context, in fiscal year 2018, Apple generated 74,000 metric tons of waste.'\n",
      "BP (2021) - Waste Generation: value=[270] unit='kt' chain_of_thought='Chain of Thought: The context states that around 270kt of hazardous and non-hazardous waste was disposed of in 2021. This value represents the total waste generation for BP in 2021.'\n",
      "BP (2022) - Waste Generation: value=[305] unit='kt' chain_of_thought='Chain of Thought: Looking at the data provided, in 2022, the total amount of waste disposed by BP is mentioned as 305 kt. This includes both hazardous and non-hazardous waste, which aligns with the concept of waste generation.'\n",
      "BP (2023) - Waste Generation: value=[481561] unit='metric tons' chain_of_thought='The context mentions that in 2023, the Company generated 481,561 metric tons of industrial waste, which was disposed of in compliance with regulations and standards. Therefore, the waste generation for BP in 2023 is 481,561 metric tons.'\n",
      "Saudi Aramco (2020) - Waste Generation: value=[231000] unit='metric tons' chain_of_thought='The context provided lists the amount of industrial waste generated by Saudi Aramco. For 2020, the waste generation is reported as 231,000 metric tons. Therefore, the answer for the waste generation in 2020 is 231,000 metric tons.'\n",
      "Saudi Aramco (2021) - Waste Generation: value=[481561] unit='metric tons' chain_of_thought=\"The context states that in 2023, Saudi Aramco generated 481,561 metric tons of industrial waste. However, it doesn't specify a different total for 2021. Assuming that the number refers to the latest available data for waste generation by the company, 481,561 metric tons is the figure to consider for the waste disposal in 2021.\"\n",
      "Saudi Aramco (2019) - Waste Generation: value=[158000] unit='metric tons' chain_of_thought='The given context states that the total amount of industrial waste, hazardous and non-hazardous, generated from operating facilities in 2019 was 158,000 metric tons.'\n",
      "Volkswagen (2019) - Waste Generation: value=[48804, 73308] unit='tonnes/year' chain_of_thought='Chain of Thought: To determine the waste generation for Volkswagen in 2019, we sum the nonhazardous waste and hazardous waste quantities for that year. The nonhazardous waste is 48,804 tonnes/year, and the hazardous waste is 73,308 tonnes/year. Therefore, the total waste generation is the sum of these two values.'\n",
      "Volkswagen (2018) - Waste Generation: value=[65, 588, 83, 943] unit='tonnes/year' chain_of_thought='Chain of Thought: From the context, waste generation for Volkswagen in 2018 includes nonhazardous waste and hazardous waste. Nonhazardous waste is 65,588 tonnes/year, and hazardous waste is 83,943 tonnes/year.'\n",
      "Amazon (2018) - Renewable Energy Usage: value=[50] unit='%' chain_of_thought='In 2018, AWS exceeded 50% renewable energy usage, according to the context provided.'\n",
      "Amazon (2019) - Renewable Energy Usage: value=[42] unit='%' chain_of_thought='In 2019, Renewable energy usage for Amazon was 42% as stated in the context.'\n",
      "Amazon (2020) - Renewable Energy Usage: value=[65] unit='%' chain_of_thought='The context states that the renewable energy usage for Amazon was 65% in 2020.'\n",
      "Amazon (2021) - Renewable Energy Usage: value=[85] unit='%' chain_of_thought='The context states that in 2021, Amazon reached 85% renewable energy across their business. Therefore, the renewable energy usage for Amazon in 2021 is 85%.'\n",
      "H&M (2017) - Renewable Energy Usage: value=[95] unit='%' chain_of_thought=\"The context mentions the percentage of renewable electricity in H&M's own operations as 96% for multiple years but does not specify a percentage for 2017. However, it does list renewable electricity usage as 96%. As the specific year is not mentioned, I will consider the previous closest mentioned value, which is 95%. Therefore, the renewable energy usage for H&M in 2017 is assumed to be 95%.\"\n",
      "H&M (2018) - Renewable Energy Usage: value=[96] unit='%' chain_of_thought=\"The document states that in 2019, 96% of electricity purchased for H&M's own operations was renewable. However, there is no explicit information about renewable energy usage in 2018. Based on the pattern seen, we can deduce that the percentage remained consistent with 2019, which is 96%, since no drop or increase for 2018 compared to other years is mentioned.\"\n",
      "H&M (2019) - Renewable Energy Usage: value=[96] unit='%' chain_of_thought=\"The context states that 96% of electricity purchased for H&M's own operations was renewable in 2019.\"\n",
      "H&M (2020) - Renewable Energy Usage: value=[96] unit='%' chain_of_thought=\"According to the context, the percentage of renewable electricity in H&M's own operations was 96% in 2020.\"\n",
      "H&M (2021) - Renewable Energy Usage: value=[96] unit='%' chain_of_thought=\"From the context, it is mentioned that 96% of electricity purchased for H&M's own operations was renewable. This percentage remained constant across the years mentioned, including 2021.\"\n",
      "H&M (2022) - Renewable Energy Usage: value=[92] unit='%' chain_of_thought=\"According to the data provided, 94 percent of electricity purchased for H&M's operations was renewable, but it also mentions that in 2022, it was 92 percent.\"\n",
      "Apple (2020) - Renewable Energy Usage: value=[2580] unit='million kWh' chain_of_thought=\"Chain of Thought: From the provided context, the renewable electricity usage for Apple's corporate facilities in 2020 was 2,580 million kWh.\"\n",
      "Apple (2022) - Renewable Energy Usage: value=[2.14] unit='billion kWh' chain_of_thought='Chain of Thought: The context provides data for the year 2022 mentioning that Apple used over 2.14 billion kWh of electricity to power its data centers and colocation facilities, and that 100 percent of this electricity was sourced from renewable energy. Therefore, the renewable energy usage for Apple in 2022 is 2.14 billion kWh.'\n",
      "Walmart (2017) - Renewable Energy Usage: value=[0.28] unit=' ' chain_of_thought=\"The context provides that an estimated 28% of Walmart's electricity needs were supplied by renewable sources in 2017. Thus, the Renewable Energy Usage for Walmart in 2017 is 28%.\"\n",
      "Google (2013) - Renewable Energy Usage: value=[35] unit='%' chain_of_thought=\"From the given information, in 2013 Google's renewable energy purchasing compared with total electricity use was 35%. Therefore, the renewable energy usage for Google in 2013 is 35%.\"\n",
      "Google (2015) - Renewable Energy Usage: value=[48] unit='%' chain_of_thought=\"The context mentions that in 2015, Google's renewable energy usage as a percentage of total electricity consumption was 48%.\"\n",
      "Google (2016) - Renewable Energy Usage: value=[61] unit='percent' chain_of_thought=\"In 2016, Google's renewable energy purchasing was 61% as they progressed towards 100% renewable energy matching.\"\n",
      "Google (2017) - Renewable Energy Usage: value=[100] unit='%' chain_of_thought='Chain of Thought: According to the context, in 2017, Google matched 100% of their annual electricity consumption with renewable energy purchases. Therefore, the renewable energy usage for Google in 2017 was 100%.'\n",
      "Google (2018) - Renewable Energy Usage: value=[100] unit='%' chain_of_thought='In 2018, Google achieved 100% renewable energy match for its electricity consumption.'\n",
      "Google (2019) - Renewable Energy Usage: value=[100] unit='percent' chain_of_thought='In 2019, Google achieved 100% renewable energy matching for its global operations.'\n",
      "Google (2020) - Renewable Energy Usage: value=[100] unit='%' chain_of_thought='Chain of Thought: According to Figure 16 in the context, Google achieved 100% renewable energy usage in 2020. Therefore, I conclude that the answer is 100%.'\n",
      "Google (2021) - Renewable Energy Usage: value=[100] unit='percent  (%)' chain_of_thought=\"Based on the retrieved context, in 2017, Google first achieved 100% renewable energy matching. The text states that as of the end of 2022, Google had achieved six consecutive years of 100% renewable energy matching on an annual basis. Therefore, in 2021, Google's renewable energy usage was still 100%.\"\n",
      "Google (2022) - Renewable Energy Usage: value=[100] unit='%' chain_of_thought='The context states that as of the end of 2022, Google achieved six consecutive years of 100% renewable energy matching on an annual basis. Therefore, the renewable energy usage for Google in 2022 is 100%. '\n",
      "Volkswagen (2023) - Renewable Energy Usage: value=[56.3] unit='%' chain_of_thought='The context states that in 2023, 56.3% of the Group’s total global electricity consumption at its production sites was accounted for by electricity from renewable sources.'\n",
      "Volkswagen (2022) - Renewable Energy Usage: value=[54.8] unit='%' chain_of_thought=\"The percentage of electricity from renewable sources for Volkswagen's production sites in 2022 was 54.8%.\"\n",
      "Amazon (2018) - Greenhouse Gas Emissions Intensity: value=[128.9] unit='grams of CO2e per dollar (USD)' chain_of_thought=\"The context states that Amazon's carbon intensity was 122.8 grams of CO2e per dollar in 2019, which was a decrease from 128.9 grams of CO2e per dollar in 2018. The 2018 value is 128.9 grams of CO2e per dollar.\"\n",
      "Amazon (2019) - Greenhouse Gas Emissions Intensity: value=[122.8] unit='grams of CO2e per dollar' chain_of_thought=\"The context states that Amazon's carbon intensity metric in 2019 was measured as 122.8 grams of carbon dioxide equivalent (CO2e) per dollar of Gross Merchandise Sales (GMS).\"\n",
      "BP (2017) - Greenhouse Gas Emissions Intensity: value=[25.9] unit='teCO2 equivalent/unit' chain_of_thought='The context provides a table with GHG emissions intensity (equity boundary) for upstream operations per thousand barrels of oil equivalent. The value for 2017 is 25.9 teCO2 equivalent/unit.'\n",
      "BP (2019) - Greenhouse Gas Emissions Intensity: value=[25.9] unit='teCO2e/unit' chain_of_thought='The context states that the Scope 1 (direct) GHG intensity (equity boundary) for BP in 2019 was 25.9 teCO2e per unit.'\n",
      "Walmart (2017) - Greenhouse Gas Emissions Intensity: value=[42.66] unit='MT CO₂e/$M' chain_of_thought=\"Chain of Thought: The greenhouse gas emissions intensity for Walmart is indicated in the provided table under 'Carbon intensity [MT CO₂e/$M]' for FY2017, where it shows a value of 42.66 MT CO₂e/$M.\"\n",
      "Walmart (2018) - Greenhouse Gas Emissions Intensity: value=[37.3] unit='MT CO2e/$M' chain_of_thought='The document states that the Carbon intensity (Scopes 1 and 2 per revenue) in FY2018 is 37.3 metric tons (MT) CO2e/$1 million.'\n",
      "Saudi Aramco (2018) - Greenhouse Gas Emissions Intensity: value=[10.2] unit='kg CO2e/boe' chain_of_thought=\"The retrieved context states that Saudi Aramco's upstream carbon intensity in 2018 was 10.2 kg CO2e/boe. Therefore, the greenhouse gas emissions intensity for Saudi Aramco in 2018 is 10.2 kg CO2e/boe.\"\n",
      "Saudi Aramco (2021) - Greenhouse Gas Emissions Intensity: value=[10.7] unit='kg CO2e/boe' chain_of_thought=\"Chain of Thought: The context states that Saudi Aramco's 2021 upstream carbon intensity figure was among the lowest globally at 10.7 kg of CO2 equivalent per barrel of oil equivalent (boe).\"\n",
      "Google (2011) - Greenhouse Gas Emissions Intensity: value=[60] unit='tCO2e/FTE' chain_of_thought='- In the given context, we have two graphs indicating emissions intensity: one for carbon intensity per unit of revenue and one for carbon intensity per FTE employee.\\n- The data for CARBON INTENSITY PER FTE EMPLOYEE shows a value of 60 tCO2e/FTE for the year 2011, as depicted in the corresponding figure 11. Therefore, the greenhouse gas emissions intensity for Google in 2011 is 60 tCO2e/FTE.'\n",
      "Google (2013) - Greenhouse Gas Emissions Intensity: value=[5.5] unit='tCO2e/BILLION US$' chain_of_thought='The document provides a figure for the carbon intensity per unit of revenue. According to Figure 9, in 2013, the carbon intensity per unit of revenue is marked at 5.5 tCO2e/BILLION US$. Therefore, the Greenhouse Gas Emissions Intensity for Google in 2013 is 5.5 tCO2e/BILLION US$.'\n",
      "Google (2014) - Greenhouse Gas Emissions Intensity: value=[4] unit='tCO2e/FTE' chain_of_thought='Chain of Thought: From the context provided, Figure 11 shows Carbon Intensity Per FTE Employee trending over the years from 2011 to 2018. In 2014, the carbon intensity per FTE employee is labeled as 4 on the graph.'\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[46], line 37\u001b[0m\n\u001b[0;32m     35\u001b[0m years_list \u001b[38;5;241m=\u001b[39m years_response\u001b[38;5;241m.\u001b[39mvalue\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m year \u001b[38;5;129;01min\u001b[39;00m years_list:\n\u001b[1;32m---> 37\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mget_response_from_openai\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mIn \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43myear\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m, what is the \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mmetric\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m for \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mcompany\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m?\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     38\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mvalue \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     39\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcompany\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00myear\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) - \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetric\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[42], line 35\u001b[0m, in \u001b[0;36mget_response_from_openai\u001b[1;34m(question)\u001b[0m\n\u001b[0;32m     33\u001b[0m context \u001b[38;5;241m=\u001b[39m retrieve_context(question)\n\u001b[0;32m     34\u001b[0m messages \u001b[38;5;241m=\u001b[39m construct_messages(context, question)\n\u001b[1;32m---> 35\u001b[0m completion \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbeta\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompletions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     36\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mMODEL\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     37\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     38\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mAnswer\u001b[49m\n\u001b[0;32m     39\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m completion\u001b[38;5;241m.\u001b[39mchoices[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmessage\u001b[38;5;241m.\u001b[39mparsed\n",
      "File \u001b[1;32mc:\\SpecProF\\Python\\lib\\site-packages\\openai\\resources\\beta\\chat\\completions.py:154\u001b[0m, in \u001b[0;36mCompletions.parse\u001b[1;34m(self, messages, model, audio, response_format, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, presence_penalty, seed, service_tier, stop, store, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[0;32m    147\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mparser\u001b[39m(raw_completion: ChatCompletion) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ParsedChatCompletion[ResponseFormatT]:\n\u001b[0;32m    148\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _parse_chat_completion(\n\u001b[0;32m    149\u001b[0m         response_format\u001b[38;5;241m=\u001b[39mresponse_format,\n\u001b[0;32m    150\u001b[0m         chat_completion\u001b[38;5;241m=\u001b[39mraw_completion,\n\u001b[0;32m    151\u001b[0m         input_tools\u001b[38;5;241m=\u001b[39mtools,\n\u001b[0;32m    152\u001b[0m     )\n\u001b[1;32m--> 154\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    155\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/chat/completions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    156\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    157\u001b[0m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\n\u001b[0;32m    158\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    159\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    160\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43maudio\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43maudio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    161\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfrequency_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    162\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunction_call\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    163\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunctions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    164\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogit_bias\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    165\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    166\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_completion_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_completion_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    167\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    168\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetadata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    169\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodalities\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodalities\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    170\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    171\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mparallel_tool_calls\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    172\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpresence_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    173\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresponse_format\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m_type_to_response_format\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    174\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseed\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    175\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mservice_tier\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    176\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstop\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    177\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstore\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    178\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    179\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    180\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtemperature\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    181\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtool_choice\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    182\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtools\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    183\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_logprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    184\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_p\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    185\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    186\u001b[0m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    187\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompletionCreateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    188\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    189\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    190\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    191\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    192\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    193\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    194\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpost_parser\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    195\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    196\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# we turn the `ChatCompletion` instance into a `ParsedChatCompletion`\u001b[39;49;00m\n\u001b[0;32m    197\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# in the `parser` function above\u001b[39;49;00m\n\u001b[0;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mType\u001b[49m\u001b[43m[\u001b[49m\u001b[43mParsedChatCompletion\u001b[49m\u001b[43m[\u001b[49m\u001b[43mResponseFormatT\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mChatCompletion\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    199\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    200\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\SpecProF\\Python\\lib\\site-packages\\openai\\_base_client.py:1277\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[1;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1263\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\n\u001b[0;32m   1264\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1265\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1272\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1273\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[0;32m   1274\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[0;32m   1275\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[0;32m   1276\u001b[0m     )\n\u001b[1;32m-> 1277\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32mc:\\SpecProF\\Python\\lib\\site-packages\\openai\\_base_client.py:954\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[0;32m    951\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    952\u001b[0m     retries_taken \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m--> 954\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    955\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    956\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    957\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    958\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    959\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries_taken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    960\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\SpecProF\\Python\\lib\\site-packages\\openai\\_base_client.py:990\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[1;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[0;32m    987\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSending HTTP Request: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, request\u001b[38;5;241m.\u001b[39mmethod, request\u001b[38;5;241m.\u001b[39murl)\n\u001b[0;32m    989\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 990\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client\u001b[38;5;241m.\u001b[39msend(\n\u001b[0;32m    991\u001b[0m         request,\n\u001b[0;32m    992\u001b[0m         stream\u001b[38;5;241m=\u001b[39mstream \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_stream_response_body(request\u001b[38;5;241m=\u001b[39mrequest),\n\u001b[0;32m    993\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    994\u001b[0m     )\n\u001b[0;32m    995\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m httpx\u001b[38;5;241m.\u001b[39mTimeoutException \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m    996\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEncountered httpx.TimeoutException\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\SpecProF\\Python\\lib\\site-packages\\httpx\\_client.py:926\u001b[0m, in \u001b[0;36mClient.send\u001b[1;34m(self, request, stream, auth, follow_redirects)\u001b[0m\n\u001b[0;32m    922\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_timeout(request)\n\u001b[0;32m    924\u001b[0m auth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_request_auth(request, auth)\n\u001b[1;32m--> 926\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_handling_auth\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    927\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    928\u001b[0m \u001b[43m    \u001b[49m\u001b[43mauth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    929\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    930\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhistory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    931\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    932\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    933\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n",
      "File \u001b[1;32mc:\\SpecProF\\Python\\lib\\site-packages\\httpx\\_client.py:954\u001b[0m, in \u001b[0;36mClient._send_handling_auth\u001b[1;34m(self, request, auth, follow_redirects, history)\u001b[0m\n\u001b[0;32m    951\u001b[0m request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(auth_flow)\n\u001b[0;32m    953\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 954\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_handling_redirects\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    955\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    956\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    957\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhistory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhistory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    958\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    959\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    960\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\SpecProF\\Python\\lib\\site-packages\\httpx\\_client.py:991\u001b[0m, in \u001b[0;36mClient._send_handling_redirects\u001b[1;34m(self, request, follow_redirects, history)\u001b[0m\n\u001b[0;32m    988\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event_hooks[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequest\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m    989\u001b[0m     hook(request)\n\u001b[1;32m--> 991\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_single_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    992\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    993\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event_hooks[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n",
      "File \u001b[1;32mc:\\SpecProF\\Python\\lib\\site-packages\\httpx\\_client.py:1027\u001b[0m, in \u001b[0;36mClient._send_single_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m   1023\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAttempted to send an async request with a sync Client instance.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1024\u001b[0m     )\n\u001b[0;32m   1026\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request\u001b[38;5;241m=\u001b[39mrequest):\n\u001b[1;32m-> 1027\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mtransport\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1029\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response\u001b[38;5;241m.\u001b[39mstream, SyncByteStream)\n\u001b[0;32m   1031\u001b[0m response\u001b[38;5;241m.\u001b[39mrequest \u001b[38;5;241m=\u001b[39m request\n",
      "File \u001b[1;32mc:\\SpecProF\\Python\\lib\\site-packages\\httpx\\_transports\\default.py:236\u001b[0m, in \u001b[0;36mHTTPTransport.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    223\u001b[0m req \u001b[38;5;241m=\u001b[39m httpcore\u001b[38;5;241m.\u001b[39mRequest(\n\u001b[0;32m    224\u001b[0m     method\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mmethod,\n\u001b[0;32m    225\u001b[0m     url\u001b[38;5;241m=\u001b[39mhttpcore\u001b[38;5;241m.\u001b[39mURL(\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    233\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mextensions,\n\u001b[0;32m    234\u001b[0m )\n\u001b[0;32m    235\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[1;32m--> 236\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_pool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    238\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resp\u001b[38;5;241m.\u001b[39mstream, typing\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m    240\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Response(\n\u001b[0;32m    241\u001b[0m     status_code\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mstatus,\n\u001b[0;32m    242\u001b[0m     headers\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mheaders,\n\u001b[0;32m    243\u001b[0m     stream\u001b[38;5;241m=\u001b[39mResponseStream(resp\u001b[38;5;241m.\u001b[39mstream),\n\u001b[0;32m    244\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mextensions,\n\u001b[0;32m    245\u001b[0m )\n",
      "File \u001b[1;32mc:\\SpecProF\\Python\\lib\\site-packages\\httpcore\\_sync\\connection_pool.py:216\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    213\u001b[0m         closing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assign_requests_to_connections()\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_connections(closing)\n\u001b[1;32m--> 216\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    218\u001b[0m \u001b[38;5;66;03m# Return the response. Note that in this case we still have to manage\u001b[39;00m\n\u001b[0;32m    219\u001b[0m \u001b[38;5;66;03m# the point at which the response is closed.\u001b[39;00m\n\u001b[0;32m    220\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response\u001b[38;5;241m.\u001b[39mstream, Iterable)\n",
      "File \u001b[1;32mc:\\SpecProF\\Python\\lib\\site-packages\\httpcore\\_sync\\connection_pool.py:196\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    192\u001b[0m connection \u001b[38;5;241m=\u001b[39m pool_request\u001b[38;5;241m.\u001b[39mwait_for_connection(timeout\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[0;32m    194\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    195\u001b[0m     \u001b[38;5;66;03m# Send the request on the assigned connection.\u001b[39;00m\n\u001b[1;32m--> 196\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpool_request\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\n\u001b[0;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    199\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ConnectionNotAvailable:\n\u001b[0;32m    200\u001b[0m     \u001b[38;5;66;03m# In some cases a connection may initially be available to\u001b[39;00m\n\u001b[0;32m    201\u001b[0m     \u001b[38;5;66;03m# handle a request, but then become unavailable.\u001b[39;00m\n\u001b[0;32m    202\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m    203\u001b[0m     \u001b[38;5;66;03m# In this case we clear the connection and try again.\u001b[39;00m\n\u001b[0;32m    204\u001b[0m     pool_request\u001b[38;5;241m.\u001b[39mclear_connection()\n",
      "File \u001b[1;32mc:\\SpecProF\\Python\\lib\\site-packages\\httpcore\\_sync\\connection.py:101\u001b[0m, in \u001b[0;36mHTTPConnection.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m     98\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connect_failed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m     99\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[1;32m--> 101\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_connection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\SpecProF\\Python\\lib\\site-packages\\httpcore\\_sync\\http11.py:143\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    141\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m Trace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse_closed\u001b[39m\u001b[38;5;124m\"\u001b[39m, logger, request) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[0;32m    142\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_response_closed()\n\u001b[1;32m--> 143\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "File \u001b[1;32mc:\\SpecProF\\Python\\lib\\site-packages\\httpcore\\_sync\\http11.py:113\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    102\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m    104\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Trace(\n\u001b[0;32m    105\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreceive_response_headers\u001b[39m\u001b[38;5;124m\"\u001b[39m, logger, request, kwargs\n\u001b[0;32m    106\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[0;32m    107\u001b[0m     (\n\u001b[0;32m    108\u001b[0m         http_version,\n\u001b[0;32m    109\u001b[0m         status,\n\u001b[0;32m    110\u001b[0m         reason_phrase,\n\u001b[0;32m    111\u001b[0m         headers,\n\u001b[0;32m    112\u001b[0m         trailing_data,\n\u001b[1;32m--> 113\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_receive_response_headers(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    114\u001b[0m     trace\u001b[38;5;241m.\u001b[39mreturn_value \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    115\u001b[0m         http_version,\n\u001b[0;32m    116\u001b[0m         status,\n\u001b[0;32m    117\u001b[0m         reason_phrase,\n\u001b[0;32m    118\u001b[0m         headers,\n\u001b[0;32m    119\u001b[0m     )\n\u001b[0;32m    121\u001b[0m network_stream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_network_stream\n",
      "File \u001b[1;32mc:\\SpecProF\\Python\\lib\\site-packages\\httpcore\\_sync\\http11.py:186\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_response_headers\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    183\u001b[0m timeout \u001b[38;5;241m=\u001b[39m timeouts\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mread\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    185\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 186\u001b[0m     event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_receive_event\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    187\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(event, h11\u001b[38;5;241m.\u001b[39mResponse):\n\u001b[0;32m    188\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\SpecProF\\Python\\lib\\site-packages\\httpcore\\_sync\\http11.py:224\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_event\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    221\u001b[0m     event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_h11_state\u001b[38;5;241m.\u001b[39mnext_event()\n\u001b[0;32m    223\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m event \u001b[38;5;129;01mis\u001b[39;00m h11\u001b[38;5;241m.\u001b[39mNEED_DATA:\n\u001b[1;32m--> 224\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_network_stream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    225\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mREAD_NUM_BYTES\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[0;32m    226\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    228\u001b[0m     \u001b[38;5;66;03m# If we feed this case through h11 we'll raise an exception like:\u001b[39;00m\n\u001b[0;32m    229\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m    230\u001b[0m     \u001b[38;5;66;03m#     httpcore.RemoteProtocolError: can't handle event type\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    234\u001b[0m     \u001b[38;5;66;03m# perspective. Instead we handle this case distinctly and treat\u001b[39;00m\n\u001b[0;32m    235\u001b[0m     \u001b[38;5;66;03m# it as a ConnectError.\u001b[39;00m\n\u001b[0;32m    236\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;241m==\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_h11_state\u001b[38;5;241m.\u001b[39mtheir_state \u001b[38;5;241m==\u001b[39m h11\u001b[38;5;241m.\u001b[39mSEND_RESPONSE:\n",
      "File \u001b[1;32mc:\\SpecProF\\Python\\lib\\site-packages\\httpcore\\_backends\\sync.py:126\u001b[0m, in \u001b[0;36mSyncStream.read\u001b[1;34m(self, max_bytes, timeout)\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_exceptions(exc_map):\n\u001b[0;32m    125\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sock\u001b[38;5;241m.\u001b[39msettimeout(timeout)\n\u001b[1;32m--> 126\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_bytes\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\SpecProF\\Python\\lib\\ssl.py:1259\u001b[0m, in \u001b[0;36mSSLSocket.recv\u001b[1;34m(self, buflen, flags)\u001b[0m\n\u001b[0;32m   1255\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1256\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1257\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[0;32m   1258\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[1;32m-> 1259\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuflen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1260\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1261\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv(buflen, flags)\n",
      "File \u001b[1;32mc:\\SpecProF\\Python\\lib\\ssl.py:1132\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[1;34m(self, len, buffer)\u001b[0m\n\u001b[0;32m   1130\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m, buffer)\n\u001b[0;32m   1131\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1132\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1133\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m SSLError \u001b[38;5;28;01mas\u001b[39;00m x:\n\u001b[0;32m   1134\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m SSL_ERROR_EOF \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msuppress_ragged_eofs:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Initialize the final DataFrame\n",
    "df_final = pd.DataFrame(columns=[\"company\", \"year\", \"metric\", \"value\", \"unit\"])\n",
    "\n",
    "# Display the available companies\n",
    "companies = set(df_sample.company_name)\n",
    "print(f\"The companies are: {', '.join(companies)}\")\n",
    "\n",
    "# Initialize variables\n",
    "add_more_metrics = True\n",
    "all_metrics = False\n",
    "\n",
    "# Prompt the user to enter a metric or 'all'\n",
    "while True:\n",
    "    metric_input = input(\"Please enter a metric you are interested in. If you need some tips, type 'help'. To use all metrics, type 'all'.\\nMetric: \").strip()\n",
    "    if metric_input.lower() == \"help\":\n",
    "        print(\"\\nAvailable ESG metrics:\")\n",
    "        print(', '.join(esg_metrics))\n",
    "        print()\n",
    "    elif metric_input.lower() == \"all\":\n",
    "        all_metrics = True\n",
    "        metrics_list = esg_metrics  # Use all metrics\n",
    "        break\n",
    "    else:\n",
    "        metrics_list = [metric_input]\n",
    "        break\n",
    "\n",
    "# Main loop to collect data\n",
    "while add_more_metrics:\n",
    "    for metric in metrics_list:\n",
    "        # Iterate over companies and collect data\n",
    "        for company in companies:\n",
    "            years_response = get_response_from_openai(f\"In which years do we have data on {metric} for {company}?\")\n",
    "            if years_response.value is not None:\n",
    "                # Clean and split the years\n",
    "                years_list = years_response.value\n",
    "                for year in years_list:\n",
    "                    response = get_response_from_openai(f\"In {year}, what is the {metric} for {company}?\")\n",
    "                    if response.value is not None:\n",
    "                        print(f\"{company} ({year}) - {metric}: {response}\")\n",
    "                        value, unit = response.value, response.unit\n",
    "                        # Create a new row and append it to df_final\n",
    "                        new_row = {\n",
    "                            \"company\": company,\n",
    "                            \"year\": year,\n",
    "                            \"metric\": metric,\n",
    "                            \"value\": value,\n",
    "                            \"unit\": unit\n",
    "                        }\n",
    "                        df_final = pd.concat([df_final, pd.DataFrame([new_row])], ignore_index=True)\n",
    "\n",
    "    # If 'all' was selected, no need to ask for more metrics\n",
    "    if all_metrics:\n",
    "        add_more_metrics = False\n",
    "    else:\n",
    "        # Ask if the user wants to add another metric\n",
    "        while True:\n",
    "            continue_input = input(\"Do you want to add another metric? (yes/no): \").strip().lower()\n",
    "            if continue_input in ['yes', 'no']:\n",
    "                break\n",
    "            else:\n",
    "                print(\"Please enter 'yes' or 'no'.\\n\")\n",
    "\n",
    "        if continue_input == 'no':\n",
    "            add_more_metrics = False\n",
    "        else:\n",
    "            # Prompt the user to enter the next metric\n",
    "            while True:\n",
    "                metric_input = input(\"Please enter the next metric you are interested in. If you need some tips, type 'help'.\\nMetric: \").strip()\n",
    "                if metric_input.lower() == \"help\":\n",
    "                    print(\"\\nAvailable ESG metrics:\")\n",
    "                    print(', '.join(esg_metrics))\n",
    "                    print()\n",
    "                else:\n",
    "                    metrics_list = [metric_input]\n",
    "                    break\n",
    "\n",
    "# Display the final DataFrame\n",
    "print(\"\\nCollected Data:\")\n",
    "print(      )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7bdd8891",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company</th>\n",
       "      <th>year</th>\n",
       "      <th>metric</th>\n",
       "      <th>value</th>\n",
       "      <th>unit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Amazon</td>\n",
       "      <td>2022</td>\n",
       "      <td>Carbon Emissions</td>\n",
       "      <td>[70.74]</td>\n",
       "      <td>metric tons CO2e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>H&amp;M</td>\n",
       "      <td>2016</td>\n",
       "      <td>Carbon Emissions</td>\n",
       "      <td>[10376, 70165]</td>\n",
       "      <td>tonnes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>H&amp;M</td>\n",
       "      <td>2017</td>\n",
       "      <td>Carbon Emissions</td>\n",
       "      <td>[70165]</td>\n",
       "      <td>tonnes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>H&amp;M</td>\n",
       "      <td>2018</td>\n",
       "      <td>Carbon Emissions</td>\n",
       "      <td>[6352, 775, 71, 62, 63]</td>\n",
       "      <td>ktonnes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>H&amp;M</td>\n",
       "      <td>2019</td>\n",
       "      <td>Carbon Emissions</td>\n",
       "      <td>[10, 376, 70, 165, 80, 541, 12, 484, 51, 206, ...</td>\n",
       "      <td>tonnes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>Saudi Aramco</td>\n",
       "      <td>2018</td>\n",
       "      <td>Greenhouse Gas Emissions Intensity</td>\n",
       "      <td>[10.2]</td>\n",
       "      <td>kg CO2e/boe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>Saudi Aramco</td>\n",
       "      <td>2021</td>\n",
       "      <td>Greenhouse Gas Emissions Intensity</td>\n",
       "      <td>[10.7]</td>\n",
       "      <td>kg CO2e/boe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>Google</td>\n",
       "      <td>2011</td>\n",
       "      <td>Greenhouse Gas Emissions Intensity</td>\n",
       "      <td>[60]</td>\n",
       "      <td>tCO2e/FTE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>Google</td>\n",
       "      <td>2013</td>\n",
       "      <td>Greenhouse Gas Emissions Intensity</td>\n",
       "      <td>[5.5]</td>\n",
       "      <td>tCO2e/BILLION US$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>Google</td>\n",
       "      <td>2014</td>\n",
       "      <td>Greenhouse Gas Emissions Intensity</td>\n",
       "      <td>[4]</td>\n",
       "      <td>tCO2e/FTE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>90 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         company  year                              metric  \\\n",
       "0         Amazon  2022                    Carbon Emissions   \n",
       "1            H&M  2016                    Carbon Emissions   \n",
       "2            H&M  2017                    Carbon Emissions   \n",
       "3            H&M  2018                    Carbon Emissions   \n",
       "4            H&M  2019                    Carbon Emissions   \n",
       "..           ...   ...                                 ...   \n",
       "85  Saudi Aramco  2018  Greenhouse Gas Emissions Intensity   \n",
       "86  Saudi Aramco  2021  Greenhouse Gas Emissions Intensity   \n",
       "87        Google  2011  Greenhouse Gas Emissions Intensity   \n",
       "88        Google  2013  Greenhouse Gas Emissions Intensity   \n",
       "89        Google  2014  Greenhouse Gas Emissions Intensity   \n",
       "\n",
       "                                                value               unit  \n",
       "0                                             [70.74]   metric tons CO2e  \n",
       "1                                      [10376, 70165]             tonnes  \n",
       "2                                             [70165]             tonnes  \n",
       "3                             [6352, 775, 71, 62, 63]            ktonnes  \n",
       "4   [10, 376, 70, 165, 80, 541, 12, 484, 51, 206, ...             tonnes  \n",
       "..                                                ...                ...  \n",
       "85                                             [10.2]        kg CO2e/boe  \n",
       "86                                             [10.7]        kg CO2e/boe  \n",
       "87                                               [60]          tCO2e/FTE  \n",
       "88                                              [5.5]  tCO2e/BILLION US$  \n",
       "89                                                [4]          tCO2e/FTE  \n",
       "\n",
       "[90 rows x 5 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9fef2aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.to_csv('data/df_final.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
